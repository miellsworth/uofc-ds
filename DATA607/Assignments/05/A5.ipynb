{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "A5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqN5rfvMRnBI",
        "colab_type": "text"
      },
      "source": [
        "## Assigment 5 (optional)\n",
        "\n",
        "Clone the Oxford Pets dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "815C1mWYRnBK",
        "colab_type": "code",
        "outputId": "644955a1-4c85-44f4-89f3-64f38d627bac",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/mpecha/Oxford-IIIT-Pet-Dataset.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Oxford-IIIT-Pet-Dataset'...\n",
            "remote: Enumerating objects: 18460, done.\u001b[K\n",
            "remote: Counting objects: 100% (18460/18460), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14780/14780), done.\u001b[K\n",
            "remote: Total 18460 (delta 3677), reused 18457 (delta 3677), pack-reused 0\n",
            "Receiving objects: 100% (18460/18460), 772.53 MiB | 8.40 MiB/s, done.\n",
            "Resolving deltas: 100% (3677/3677), done.\n",
            "Checking out files: 100% (18475/18475), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfu-0hq9RnBN",
        "colab_type": "text"
      },
      "source": [
        "### 1. \n",
        "\n",
        "- Construct a `pandas` dataframe with one column containing the paths to the images subdirectory of `Oxford-IIIT-Pet-Dataset`, one column labelling each image as a cat or a dog, and one column containing the breed.\n",
        "- Split the dataframe into two randomly generated subsets corresponding to a training/testing split of the dataset. \n",
        "- Construct an instance of `keras.preprocessing.image.ImageDataGenerator`. Use its `flow_from_dataset` to construct generators for your training and testing sets.\n",
        "- Use transfer learning with a pretrained network of your choice to \n",
        "  - Classify the images as dogs or cats\n",
        "  - Classify the breed of the animal.\n",
        "  - Experiment with data augmentation facilities available through the `ImageDataGenerator` class. Does it help with either of the above tasks?\n",
        "- Extract the image dimensions and their bounding boxes from the annotation files in the `annotations/xmls` subdirectory of `Oxford-IIIT-Pet-Dataset`. Construct a pandas dataframe with one column containing the paths to the images subdirectory of `Oxford-IIIT-Pet-Dataset`, in addition to columns containing normalizations of `xmin`, `ymin`, `xmax`, `ymax`.\n",
        "- Split the dataframe into two randomly generated subsets corresponding to a training/testing split of the dataset. \n",
        "- Construct an instance of `keras.preprocessing.image.ImageDataGenerator`. Use its `flow_from_dataset` to construct generators for your training and testing sets.\n",
        "- Use transfer learning with a pretrained network of your choice to learn the locations of the bounding boxes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3psokDcRnBO",
        "colab_type": "text"
      },
      "source": [
        "### 2.\n",
        "\n",
        "- Extract the image dimensions and their bounding boxes from the annotation files in the `annotations/xmls` subdirectory of `Oxford-IIIT-Pet-Dataset`. Construct a pandas dataframe with one column containing the paths to the images subdirectory of `Oxford-IIIT-Pet-Dataset`, in addition to columns containing normalizations of `xmin`, `ymin`, `xmax`, `ymax`.\n",
        "- Split the dataframe into two randomly generated subsets corresponding to a training/testing split of the dataset. \n",
        "- Construct an instance of `keras.preprocessing.image.ImageDataGenerator`. Use its `flow_from_dataset` to construct generators for your training and testing sets.\n",
        "- Use transfer learning with a pretrained network of your choice to learn the locations of the bounding boxes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MWzcnv_RnBO",
        "colab_type": "text"
      },
      "source": [
        "### 3.\n",
        "\n",
        "- Load all the images that possess bounding box annotations, resized to common height and width, into a 4-dimensional tensor, `X`. Construct a tensor `Y` containing the normalizations of the associated bounding boxes. Split `X` and `Y` into training and testing sets.\n",
        "- Flip each image in `X` horizontally with probability 0.5, and transforms the annotations in `Y` to match.\n",
        "- Use transfer learning with a pretrained network of your choice to learn the locations of the bounding boxes. Apply the above flip/transform operation after each epoch of training. Does this data augmentation help?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGfiDSqvRnBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}